{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ea9eb35-6545-4561-adfb-cb479deed93e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T22:01:42.543134Z",
     "iopub.status.busy": "2024-10-10T22:01:42.542203Z",
     "iopub.status.idle": "2024-10-10T22:01:42.548555Z",
     "shell.execute_reply": "2024-10-10T22:01:42.547773Z",
     "shell.execute_reply.started": "2024-10-10T22:01:42.543088Z"
    }
   },
   "outputs": [],
   "source": [
    "from importlib.metadata import version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931397df-1a4e-42df-8043-237691145331",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install protobuf sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a78b062-5316-4e9a-892f-e8d3e561c81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33c0bfac-cd0d-4260-ba8f-4861c7b97fcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T22:09:22.490362Z",
     "iopub.status.busy": "2024-10-10T22:09:22.489945Z",
     "iopub.status.idle": "2024-10-10T22:09:22.501686Z",
     "shell.execute_reply": "2024-10-10T22:09:22.500492Z",
     "shell.execute_reply.started": "2024-10-10T22:09:22.490325Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.45.2'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('transformers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45d97ce-e15e-4de5-af77-82dce7f4ab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "219d838a-04ee-4183-852b-1a3bde00da30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T22:01:57.171194Z",
     "iopub.status.busy": "2024-10-10T22:01:57.170581Z",
     "iopub.status.idle": "2024-10-10T22:01:57.183253Z",
     "shell.execute_reply": "2024-10-10T22:01:57.182546Z",
     "shell.execute_reply.started": "2024-10-10T22:01:57.171159Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.30.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('diffusers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5bfa2d-2fac-49fa-a75a-66b165def16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade optimum-quanto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7defe11-6afe-45ab-a07c-bf1400baeb5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T22:02:32.522981Z",
     "iopub.status.busy": "2024-10-10T22:02:32.522371Z",
     "iopub.status.idle": "2024-10-10T22:02:32.533265Z",
     "shell.execute_reply": "2024-10-10T22:02:32.532082Z",
     "shell.execute_reply.started": "2024-10-10T22:02:32.522929Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.5'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('optimum-quanto')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3720f270-f97c-4ed3-8d48-d3525101cd2b",
   "metadata": {},
   "source": [
    "https://huggingface.co/black-forest-labs/FLUX.1-schnell\n",
    "\n",
    "https://huggingface.co/docs/diffusers/main/en/api/pipelines/flux\n",
    "\n",
    "https://gist.github.com/sayakpaul/b664605caf0aa3bf8585ab109dd5ac9c\n",
    "\n",
    "https://gist.github.com/sayakpaul/e1f28e86d0756d587c0b898c73822c47\n",
    "\n",
    "https://github.com/huggingface/diffusers/issues/9165\n",
    "\n",
    "https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/981\n",
    "\n",
    "https://huggingface.co/silveroxides/flux1-nf4-weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "437dfa08-b981-4a22-ac42-d6ca5b2fb5e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T22:28:15.416128Z",
     "iopub.status.busy": "2024-10-10T22:28:15.415987Z",
     "iopub.status.idle": "2024-10-10T22:28:18.856249Z",
     "shell.execute_reply": "2024-10-10T22:28:18.854796Z",
     "shell.execute_reply.started": "2024-10-10T22:28:15.416115Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from optimum.quanto import freeze, qfloat8, qint4, quantize\n",
    "from diffusers import FlowMatchEulerDiscreteScheduler, AutoencoderKL\n",
    "from diffusers.models.transformers.transformer_flux import FluxTransformer2DModel\n",
    "from diffusers.pipelines.flux.pipeline_flux import FluxPipeline\n",
    "from transformers import CLIPTextModel, CLIPTokenizer,T5EncoderModel, T5TokenizerFast\n",
    "\n",
    "# Load the model\n",
    "scheduler = FlowMatchEulerDiscreteScheduler.from_pretrained(\"black-forest-labs/FLUX.1-schnell\", subfolder=\"scheduler\", revision=\"refs/pr/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3045f0c-ab67-416f-a5df-22c86fedda1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T22:28:18.857693Z",
     "iopub.status.busy": "2024-10-10T22:28:18.857346Z",
     "iopub.status.idle": "2024-10-10T22:28:20.643433Z",
     "shell.execute_reply": "2024-10-10T22:28:20.642567Z",
     "shell.execute_reply.started": "2024-10-10T22:28:18.857671Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model download: 1.71 GB\n",
    "# VRAM before: 180 MB\n",
    "# VRAM after: 610 MB\n",
    "\n",
    "text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\", torch_dtype=torch.bfloat16).to(\"cuda\")\n",
    "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\", torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69d29861-4199-48ad-9637-9d504433d80e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T22:28:20.644353Z",
     "iopub.status.busy": "2024-10-10T22:28:20.643992Z",
     "iopub.status.idle": "2024-10-10T22:37:33.780699Z",
     "shell.execute_reply": "2024-10-10T22:37:33.773403Z",
     "shell.execute_reply.started": "2024-10-10T22:28:20.644340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba54a78808b42a699ee226355c8fd6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7cfe5c43b3a43319a97521dabf34ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
      "/root/miniforge3/envs/pytorch-2.4/lib/python3.12/site-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5EncoderModel(\n",
       "  (shared): Embedding(32128, 4096)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 4096)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): QLinear(in_features=4096, out_features=4096, bias=False)\n",
       "              (k): QLinear(in_features=4096, out_features=4096, bias=False)\n",
       "              (v): QLinear(in_features=4096, out_features=4096, bias=False)\n",
       "              (o): QLinear(in_features=4096, out_features=4096, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 64)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): QLinear(in_features=4096, out_features=10240, bias=False)\n",
       "              (wi_1): QLinear(in_features=4096, out_features=10240, bias=False)\n",
       "              (wo): QLinear(in_features=10240, out_features=4096, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): QLinear(in_features=4096, out_features=4096, bias=False)\n",
       "              (k): QLinear(in_features=4096, out_features=4096, bias=False)\n",
       "              (v): QLinear(in_features=4096, out_features=4096, bias=False)\n",
       "              (o): QLinear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): QLinear(in_features=4096, out_features=10240, bias=False)\n",
       "              (wi_1): QLinear(in_features=4096, out_features=10240, bias=False)\n",
       "              (wo): QLinear(in_features=10240, out_features=4096, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model download: 9.52 GB\n",
    "# VRAM before: 610 MB\n",
    "# VRAM after: \n",
    "\n",
    "text_encoder_2 = T5EncoderModel.from_pretrained(\"black-forest-labs/FLUX.1-schnell\", subfolder=\"text_encoder_2\", torch_dtype=torch.bfloat16, revision=\"refs/pr/1\")\n",
    "tokenizer_2 = T5TokenizerFast.from_pretrained(\"black-forest-labs/FLUX.1-schnell\", subfolder=\"tokenizer_2\", torch_dtype=torch.bfloat16, revision=\"refs/pr/1\")\n",
    "\n",
    "# quantize to 8-bit to fit on an RTX 4090\n",
    "# quantize(text_encoder_2, weights=qfloat8)\n",
    "# quantize to 4-bit to fit on an RTX 3070\n",
    "quantize(text_encoder_2, weights=qint4)\n",
    "freeze(text_encoder_2)\n",
    "text_encoder_2.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89ad18c-31e4-42fe-8ac5-9b50524bea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model download: GB\n",
    "# VRAM before: \n",
    "# VRAM after: \n",
    "\n",
    "vae = AutoencoderKL.from_pretrained(\"black-forest-labs/FLUX.1-schnell\", subfolder=\"vae\", torch_dtype=torch.bfloat16, revision=\"refs/pr/1\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024fada4-980f-48ca-a7de-3caa8de7d7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model download: GB\n",
    "# VRAM before: \n",
    "# VRAM after: \n",
    "\n",
    "transformer = FluxTransformer2DModel.from_pretrained(\"black-forest-labs/FLUX.1-schnell\", subfolder=\"transformer\", torch_dtype=torch.bfloat16, revision=\"refs/pr/1\")\n",
    "# quantize to 8-bit to fit on an RTX 4090\n",
    "#quantize(transformer, weights=qfloat8)\n",
    "# quantize to 4-bit to fit on an RTX 3070\n",
    "quantize(transformer, weights=qint4)\n",
    "freeze(transformer)\n",
    "transformer.to(\"cuda\")\n",
    "\n",
    "pipe = FluxPipeline(\n",
    "    scheduler=scheduler,\n",
    "    text_encoder=text_encoder,\n",
    "    tokenizer=tokenizer,\n",
    "    text_encoder_2=None,\n",
    "    tokenizer_2=tokenizer_2,\n",
    "    vae=vae,\n",
    "    transformer=None,\n",
    ")\n",
    "pipe.text_encoder_2 = text_encoder_2\n",
    "pipe.transformer = transformer\n",
    "pipe.enable_model_cpu_offload()\n",
    "\n",
    "def generate_image(prompt):\n",
    "    # Generate image from prompt\n",
    "    image = pipe(\n",
    "        prompt=prompt, \n",
    "        width=1024,\n",
    "        height=1024,\n",
    "        num_inference_steps=4, \n",
    "        generator=torch.Generator().manual_seed(int(time.time())),\n",
    "        guidance_scale=3.5,\n",
    "    ).images[0]\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a578bb8b-f50a-40e5-92b1-15995efcadf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_image(\"un lapin dort dans son un panier\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wordslab-images",
   "language": "python",
   "name": "wordslab-images"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
